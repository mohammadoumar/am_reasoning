{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files_directory = \"/Utilisateurs/umushtaq/am_reasoning/abstRCT/raw_files/train/neoplasm_train\"\n",
    "dev_files_directory = \"/Utilisateurs/umushtaq/am_reasoning/abstRCT/raw_files/dev/neoplasm_dev\"\n",
    "neo_test_files_directory = \"/Utilisateurs/umushtaq/am_reasoning/abstRCT/raw_files/test/neoplasm_test\"\n",
    "mix_test_files_directory = \"/Utilisateurs/umushtaq/am_reasoning/abstRCT/raw_files/test/mixed_test\"\n",
    "gla_test_files_directory = \"/Utilisateurs/umushtaq/am_reasoning/abstRCT/raw_files/test/glaucoma_test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process ANN files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_ann_files(dir):\n",
    "    \n",
    "#     component_data = []\n",
    "#     relations_data = []\n",
    "    \n",
    "#     for filename in tqdm([f for f in os.listdir(dir) if f.endswith('.ann')], desc=\"Parsing annotation files for components ...\"):\n",
    "    \n",
    "#         #print(\"processing: \" + filename)\n",
    "#         #if filename.endswith(\".ann\"):  # Process only text files\n",
    "#         file_path = os.path.join(dir, filename)\n",
    "        \n",
    "#         with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "#             for line in file:\n",
    "#                 parts = line.strip().split(\"\\t\")\n",
    "#                 #print(parts)\n",
    "#                 # Process \"T\" lines (claims/premises)\n",
    "#                 if line.startswith(\"T\"):\n",
    "#                     t_id = parts[0]  # Extract T ID (e.g., T1)\n",
    "#                     t_type = parts[1].split(\" \")[0]  # Extract type (e.g., MajorClaim, Claim, Premise)\n",
    "#                     t_s_bound = parts[1].split(\" \")[1]\n",
    "#                     t_e_bound = parts[1].split(\" \")[2]\n",
    "#                     text = parts[2] #if len(parts) > 3 else \"\"  # Extract text if available\n",
    "#                     component_data.append([\"T\", filename, t_id, t_type, t_s_bound, t_e_bound, text])\n",
    "                    \n",
    "#     for filename in tqdm([f for f in os.listdir(dir) if f.endswith('.ann')], desc=\"Parsing annotation files for relations ... \"):\n",
    "    \n",
    "#         #print(\"processing: \" + filename)\n",
    "#         #if filename.endswith(\".ann\"):  # Process only text files\n",
    "#         file_path = os.path.join(dir, filename)\n",
    "        \n",
    "#         with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "#             has_relation = False\n",
    "#             for line in file:\n",
    "#                 parts = line.strip().split(\"\\t\")\n",
    "#                 #print(parts)\n",
    "#                 # Process \"T\" lines (claims/premises)\n",
    "#                 if line.startswith(\"R\"):\n",
    "#                     has_relation = True\n",
    "#                     parts = line.strip().split()\n",
    "#                     relation_type = parts[1]  # \"supports\" or \"attacks\"\n",
    "#                     arg1 = parts[2].split(\":\")[1]  # Extract T value from Arg1\n",
    "#                     arg2 = parts[3].split(\":\")[1]  # Extract T value from Arg2\n",
    "#                     relations_data.append([\"R\", filename, arg1, arg2, relation_type])\n",
    "                    \n",
    "#             if not has_relation:\n",
    "#                 relations_data.append([\"R\", filename, None, None, None])\n",
    "                    \n",
    "#     return component_data, relations_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ann_files(dir):\n",
    "    \n",
    "    component_data = []\n",
    "    relations_data = []\n",
    "    \n",
    "    for filename in tqdm([f for f in os.listdir(dir) if f.endswith('.ann')], desc=\"Parsing annotation files ...\"):\n",
    "    \n",
    "        file_path = os.path.join(dir, filename)\n",
    "        \n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            has_relation = False\n",
    "            for line in file:\n",
    "                parts = line.strip().split(\"\\t\")\n",
    "                #print(parts)\n",
    "                # Process \"T\" lines (claims/premises)\n",
    "                if line.startswith(\"T\"):\n",
    "                    t_id = parts[0]  # Extract T ID (e.g., T1)\n",
    "                    t_type = parts[1].split(\" \")[0]  # Extract type (e.g., MajorClaim, Claim, Premise)\n",
    "                    t_s_bound = parts[1].split(\" \")[1]\n",
    "                    t_e_bound = parts[1].split(\" \")[2]\n",
    "                    text = parts[2] #if len(parts) > 3 else \"\"  # Extract text if available\n",
    "                    component_data.append([\"T\", filename, t_id, t_type, t_s_bound, t_e_bound, text])                    \n",
    "                    \n",
    "                elif line.startswith(\"R\"):\n",
    "                    has_relation = True\n",
    "                    parts = line.strip().split()\n",
    "                    relation_type = parts[1]  # \"supports\" or \"attacks\"\n",
    "                    arg1 = parts[2].split(\":\")[1]  # Extract T value from Arg1\n",
    "                    arg2 = parts[3].split(\":\")[1]  # Extract T value from Arg2\n",
    "                    relations_data.append([\"R\", filename, arg1, arg2, relation_type])\n",
    "                    \n",
    "            if not has_relation:\n",
    "                relations_data.append([\"R\", filename, None, None, None])\n",
    "                    \n",
    "    return component_data, relations_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing annotation files ...: 100%|██████████| 350/350 [00:00<00:00, 499.20it/s]\n"
     ]
    }
   ],
   "source": [
    "train_component_data, train_relations_data = process_ann_files(train_files_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing annotation files ...: 100%|██████████| 50/50 [00:00<00:00, 549.27it/s]\n"
     ]
    }
   ],
   "source": [
    "dev_component_data, dev_relations_data = process_ann_files(dev_files_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing annotation files ...: 100%|██████████| 100/100 [00:00<00:00, 556.21it/s]\n"
     ]
    }
   ],
   "source": [
    "neo_test_component_data, neo_test_relations_data = process_ann_files(neo_test_files_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing annotation files ...:   3%|▎         | 3/100 [00:00<00:03, 29.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing annotation files ...: 100%|██████████| 100/100 [00:00<00:00, 377.88it/s]\n"
     ]
    }
   ],
   "source": [
    "mix_test_component_data, mix_test_relations_data = process_ann_files(mix_test_files_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing annotation files ...:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing annotation files ...: 100%|██████████| 100/100 [00:00<00:00, 600.60it/s]\n"
     ]
    }
   ],
   "source": [
    "gla_test_component_data, gla_test_relations_data = process_ann_files(gla_test_files_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataframes(components, relations):\n",
    "    \n",
    "    comp_df = pd.DataFrame(components)\n",
    "    comp_df.columns = [\"type_indicator\", \"filename\", \"ac_id\", \"ac_type\", \"ac_start_bound\", \"ac_end_bound\", \"ac\"]\n",
    "    \n",
    "    r_df = pd.DataFrame(relations)\n",
    "    r_df.columns = [\"type_indicator\", \"filename\", \"source\", \"target\", \"relation_type\"]\n",
    "    \n",
    "    train_gdf = comp_df.groupby([\"filename\"], sort=False).agg({\n",
    "    'type_indicator': list,\n",
    "    'ac_id': list,\n",
    "    \"ac_type\": list,\n",
    "    'ac_start_bound': list,\n",
    "    'ac_end_bound': list,\n",
    "    'ac': list,\n",
    "}).reset_index()\n",
    "    \n",
    "    rtrain_gdf = r_df.groupby([\"filename\"], sort=False).agg({\n",
    "    'type_indicator': list,\n",
    "    'source': list,\n",
    "    \"target\": list,\n",
    "    'relation_type': list,\n",
    "}).reset_index()\n",
    "    \n",
    "    return train_gdf.merge(rtrain_gdf, on=\"filename\")   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = build_dataframes(train_component_data, train_relations_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df = build_dataframes(dev_component_data, dev_relations_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gla_test_df = build_dataframes(gla_test_component_data, gla_test_relations_data)\n",
    "mix_test_df = build_dataframes(mix_test_component_data, mix_test_relations_data)\n",
    "neo_test_df = build_dataframes(neo_test_component_data, neo_test_relations_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((350, 11), (50, 11), (100, 11), (100, 11), (100, 11))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, dev_df.shape, gla_test_df.shape, mix_test_df.shape, neo_test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_files(dir):\n",
    "    text_data = []\n",
    "\n",
    "    for filename in tqdm([f for f in os.listdir(dir) if f.endswith('.txt')], desc=\"Parsing text files ...\"):\n",
    "        file_path = os.path.join(dir, filename)\n",
    "\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            full_text = file.read()\n",
    "            text_data.append([filename, filename.replace(\".txt\", \".ann\"), full_text])\n",
    "\n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing text files ...: 100%|██████████| 350/350 [00:00<00:00, 519.94it/s]\n"
     ]
    }
   ],
   "source": [
    "train_texts = process_text_files(train_files_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing text files ...:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing text files ...: 100%|██████████| 50/50 [00:00<00:00, 602.62it/s]\n"
     ]
    }
   ],
   "source": [
    "dev_texts = process_text_files(dev_files_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing text files ...:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing text files ...: 100%|██████████| 100/100 [00:00<00:00, 567.42it/s]\n",
      "Parsing text files ...: 100%|██████████| 100/100 [00:00<00:00, 573.32it/s]\n",
      "Parsing text files ...: 100%|██████████| 100/100 [00:00<00:00, 681.12it/s]\n"
     ]
    }
   ],
   "source": [
    "gla_test_texts = process_text_files(gla_test_files_directory)\n",
    "mix_test_texts = process_text_files(mix_test_files_directory)\n",
    "neo_test_texts = process_text_files(neo_test_files_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350, 50, 100, 100, 100)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_texts), len(dev_texts), len(gla_test_texts), len(mix_test_texts), len(neo_test_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts_df = pd.DataFrame(train_texts)\n",
    "dev_texts_df = pd.DataFrame(dev_texts)\n",
    "gla_test_texts_df = pd.DataFrame(gla_test_texts)\n",
    "mix_test_texts_df = pd.DataFrame(mix_test_texts)\n",
    "neo_test_texts_df = pd.DataFrame(neo_test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts_df.columns = [\"text_file\", \"filename\", \"abstract_text\"]\n",
    "dev_texts_df.columns = [\"text_file\", \"filename\", \"abstract_text\"]\n",
    "gla_test_texts_df.columns = [\"text_file\", \"filename\", \"abstract_text\"]\n",
    "mix_test_texts_df.columns = [\"text_file\", \"filename\", \"abstract_text\"]\n",
    "neo_test_texts_df.columns = [\"text_file\", \"filename\", \"abstract_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_abs = train_df.merge(train_texts_df, on=\"filename\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df_abs = dev_df.merge(dev_texts_df, on=\"filename\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gla_test_df_abs = gla_test_df.merge(gla_test_texts_df, on=\"filename\")\n",
    "mix_test_df_abs = mix_test_df.merge(mix_test_texts_df, on=\"filename\")\n",
    "neo_test_df_abs = neo_test_df.merge(neo_test_texts_df, on=\"filename\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((350, 13), (50, 13), (100, 13), (100, 13), (100, 13))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_abs.shape, dev_df_abs.shape, gla_test_df_abs.shape, mix_test_df_abs.shape, neo_test_df_abs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "### Adjust Relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((350, 13), (50, 13), (100, 13), (100, 13), (100, 13))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_abs.shape, dev_df_abs.shape, gla_test_df_abs.shape, mix_test_df_abs.shape, neo_test_df_abs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Partial Attack -> Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_rel(row):\n",
    "    \n",
    "    return [\"Attack\" if elem == \"Partial-Attack\" else elem for elem in row.relation_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_abs['relation_type'] = train_df_abs.apply(lambda row: process_rel(row), axis=1)\n",
    "dev_df_abs['relation_type'] = dev_df_abs.apply(lambda row: process_rel(row), axis=1)\n",
    "gla_test_df_abs['relation_type'] = gla_test_df_abs.apply(lambda row: process_rel(row), axis=1)\n",
    "mix_test_df_abs['relation_type'] = mix_test_df_abs.apply(lambda row: process_rel(row), axis=1)\n",
    "neo_test_df_abs['relation_type'] = neo_test_df_abs.apply(lambda row: process_rel(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>type_indicator_x</th>\n",
       "      <th>ac_id</th>\n",
       "      <th>ac_type</th>\n",
       "      <th>ac_start_bound</th>\n",
       "      <th>ac_end_bound</th>\n",
       "      <th>ac</th>\n",
       "      <th>type_indicator_y</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>relation_type</th>\n",
       "      <th>text_file</th>\n",
       "      <th>abstract_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10561201.ann</td>\n",
       "      <td>[T, T, T, T, T, T, T]</td>\n",
       "      <td>[T1, T2, T3, T4, T6, T7, T8]</td>\n",
       "      <td>[MajorClaim, Premise, Premise, Premise, Premis...</td>\n",
       "      <td>[1, 992, 1063, 1188, 1452, 1569, 1769]</td>\n",
       "      <td>[162, 1058, 1187, 1447, 1568, 1768, 1945]</td>\n",
       "      <td>[A combination of mitoxantrone plus prednisone...</td>\n",
       "      <td>[R, R, R, R, R, R]</td>\n",
       "      <td>[T8, T2, T3, T6, T4, T7]</td>\n",
       "      <td>[T1, T8, T8, T8, T8, T1]</td>\n",
       "      <td>[Support, Support, Support, Support, Support, ...</td>\n",
       "      <td>10561201.txt</td>\n",
       "      <td>A combination of mitoxantrone plus prednisone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10561203.ann</td>\n",
       "      <td>[T, T, T, T, T, T, T]</td>\n",
       "      <td>[T1, T3, T4, T5, T6, T7, T8]</td>\n",
       "      <td>[Claim, Premise, Premise, Premise, Premise, Pr...</td>\n",
       "      <td>[1, 1354, 1443, 1593, 1828, 1979, 2056]</td>\n",
       "      <td>[318, 1442, 1592, 1827, 1978, 2055, 2167]</td>\n",
       "      <td>[In endocrine therapy trials in advanced breas...</td>\n",
       "      <td>[R, R, R, R, R]</td>\n",
       "      <td>[T7, T3, T4, T5, T6]</td>\n",
       "      <td>[T8, T8, T8, T8, T8]</td>\n",
       "      <td>[Attack, Support, Support, Support, Attack]</td>\n",
       "      <td>10561203.txt</td>\n",
       "      <td>In endocrine therapy trials in advanced breas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10653877.ann</td>\n",
       "      <td>[T, T, T, T, T, T, T, T, T]</td>\n",
       "      <td>[T1, T2, T3, T4, T5, T6, T7, T8, T9]</td>\n",
       "      <td>[Claim, Premise, Premise, Premise, Premise, Pr...</td>\n",
       "      <td>[1, 957, 1204, 1297, 1465, 1612, 1865, 1938, 2...</td>\n",
       "      <td>[156, 1203, 1296, 1464, 1611, 1864, 1928, 2001...</td>\n",
       "      <td>[Treatment with cisplatin-based chemotherapy p...</td>\n",
       "      <td>[R, R, R, R, R]</td>\n",
       "      <td>[T8, T6, T2, T4, T5]</td>\n",
       "      <td>[T9, T9, T9, T9, T9]</td>\n",
       "      <td>[Support, Support, Support, Support, Support]</td>\n",
       "      <td>10653877.txt</td>\n",
       "      <td>Treatment with cisplatin-based chemotherapy p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10675381.ann</td>\n",
       "      <td>[T, T, T, T, T, T, T, T]</td>\n",
       "      <td>[T1, T2, T3, T4, T5, T6, T7, T8]</td>\n",
       "      <td>[MajorClaim, Premise, Premise, Premise, Premis...</td>\n",
       "      <td>[218, 1028, 1209, 1395, 1580, 1647, 1844, 2193]</td>\n",
       "      <td>[449, 1208, 1394, 1579, 1646, 1843, 2152, 2288]</td>\n",
       "      <td>[In nonrandomized studies involving patients w...</td>\n",
       "      <td>[R, R, R, R, R]</td>\n",
       "      <td>[T2, T4, T5, T6, T7]</td>\n",
       "      <td>[T8, T8, T8, T8, T8]</td>\n",
       "      <td>[Support, Support, Support, Support, Support]</td>\n",
       "      <td>10675381.txt</td>\n",
       "      <td>Extracellular adenosine 5'-triphosphate (ATP)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10735887.ann</td>\n",
       "      <td>[T, T, T, T, T, T, T]</td>\n",
       "      <td>[T1, T2, T3, T4, T5, T6, T7]</td>\n",
       "      <td>[Premise, Premise, Premise, Premise, Claim, Pr...</td>\n",
       "      <td>[552, 678, 758, 1102, 1196, 1228, 1306]</td>\n",
       "      <td>[677, 757, 1101, 1195, 1227, 1305, 1555]</td>\n",
       "      <td>[Overall objective response (OR) rates were hi...</td>\n",
       "      <td>[R, R, R, R]</td>\n",
       "      <td>[T1, T3, T4, T5]</td>\n",
       "      <td>[T7, T7, T7, T7]</td>\n",
       "      <td>[Support, Support, Support, Support]</td>\n",
       "      <td>10735887.txt</td>\n",
       "      <td>This phase III, double-blind, randomized, mul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>9807987.ann</td>\n",
       "      <td>[T, T, T, T, T]</td>\n",
       "      <td>[T1, T2, T3, T4, T5]</td>\n",
       "      <td>[Premise, Premise, Premise, Premise, Claim]</td>\n",
       "      <td>[812, 1026, 1140, 1342, 1469]</td>\n",
       "      <td>[1025, 1139, 1341, 1468, 1760]</td>\n",
       "      <td>[With a median follow-up of 13 months, the ove...</td>\n",
       "      <td>[R, R, R]</td>\n",
       "      <td>[T4, T3, T1]</td>\n",
       "      <td>[T5, T5, T5]</td>\n",
       "      <td>[Support, Support, Support]</td>\n",
       "      <td>9807987.txt</td>\n",
       "      <td>In phase II studies, irinotecan is active in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>9849452.ann</td>\n",
       "      <td>[T, T, T, T, T, T, T, T, T]</td>\n",
       "      <td>[T1, T2, T3, T4, T5, T6, T7, T8, T9]</td>\n",
       "      <td>[Premise, Premise, Premise, Premise, Premise, ...</td>\n",
       "      <td>[983, 1124, 1187, 1250, 1327, 1349, 1503, 1624...</td>\n",
       "      <td>[1123, 1186, 1249, 1326, 1348, 1502, 1623, 166...</td>\n",
       "      <td>[Patients in the chemotherapy group reported b...</td>\n",
       "      <td>[R, R, R, R, R]</td>\n",
       "      <td>[T5, T1, T3, T6, T7]</td>\n",
       "      <td>[T4, T9, T2, T9, T9]</td>\n",
       "      <td>[Attack, Support, Attack, Support, Support]</td>\n",
       "      <td>9849452.txt</td>\n",
       "      <td>The aim of the present trial was to evaluate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>9849454.ann</td>\n",
       "      <td>[T, T, T, T, T, T]</td>\n",
       "      <td>[T1, T2, T3, T4, T5, T6]</td>\n",
       "      <td>[Premise, Premise, Premise, Premise, Claim, Cl...</td>\n",
       "      <td>[1149, 1215, 1381, 1507, 2258, 2523]</td>\n",
       "      <td>[1214, 1380, 1506, 1699, 2522, 2655]</td>\n",
       "      <td>[Complete remission was achieved in 91% (170/1...</td>\n",
       "      <td>[R, R, R, R]</td>\n",
       "      <td>[T1, T4, T3, T2]</td>\n",
       "      <td>[T6, T6, T5, T5]</td>\n",
       "      <td>[Support, Support, Support, Support]</td>\n",
       "      <td>9849454.txt</td>\n",
       "      <td>The second International Society of Paediatri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>9850014.ann</td>\n",
       "      <td>[T, T, T, T, T, T]</td>\n",
       "      <td>[T1, T2, T3, T4, T5, T6]</td>\n",
       "      <td>[Premise, Premise, Premise, Premise, Premise, ...</td>\n",
       "      <td>[891, 1041, 1139, 1264, 1357, 1578]</td>\n",
       "      <td>[1040, 1138, 1263, 1356, 1577, 1770]</td>\n",
       "      <td>[An objective response (complete [CR] or parti...</td>\n",
       "      <td>[R, R, R]</td>\n",
       "      <td>[T4, T5, T3]</td>\n",
       "      <td>[T6, T6, T6]</td>\n",
       "      <td>[Support, Support, Support]</td>\n",
       "      <td>9850014.txt</td>\n",
       "      <td>We report results of a randomized prospective...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>9890172.ann</td>\n",
       "      <td>[T, T, T, T, T, T]</td>\n",
       "      <td>[T1, T2, T5, T6, T7, T8]</td>\n",
       "      <td>[Claim, Premise, Premise, Premise, Premise, Cl...</td>\n",
       "      <td>[1, 1260, 1451, 1564, 1644, 1737]</td>\n",
       "      <td>[154, 1450, 1563, 1643, 1736, 1841]</td>\n",
       "      <td>[Vinorelbine, a semisynthetic vinca alkaloid, ...</td>\n",
       "      <td>[R, R, R, R, R]</td>\n",
       "      <td>[T8, T5, T6, T2, T7]</td>\n",
       "      <td>[T1, T8, T8, T8, T8]</td>\n",
       "      <td>[Support, Support, Support, Support, Support]</td>\n",
       "      <td>9890172.txt</td>\n",
       "      <td>Vinorelbine, a semisynthetic vinca alkaloid, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename             type_indicator_x  \\\n",
       "0    10561201.ann        [T, T, T, T, T, T, T]   \n",
       "1    10561203.ann        [T, T, T, T, T, T, T]   \n",
       "2    10653877.ann  [T, T, T, T, T, T, T, T, T]   \n",
       "3    10675381.ann     [T, T, T, T, T, T, T, T]   \n",
       "4    10735887.ann        [T, T, T, T, T, T, T]   \n",
       "..            ...                          ...   \n",
       "345   9807987.ann              [T, T, T, T, T]   \n",
       "346   9849452.ann  [T, T, T, T, T, T, T, T, T]   \n",
       "347   9849454.ann           [T, T, T, T, T, T]   \n",
       "348   9850014.ann           [T, T, T, T, T, T]   \n",
       "349   9890172.ann           [T, T, T, T, T, T]   \n",
       "\n",
       "                                    ac_id  \\\n",
       "0            [T1, T2, T3, T4, T6, T7, T8]   \n",
       "1            [T1, T3, T4, T5, T6, T7, T8]   \n",
       "2    [T1, T2, T3, T4, T5, T6, T7, T8, T9]   \n",
       "3        [T1, T2, T3, T4, T5, T6, T7, T8]   \n",
       "4            [T1, T2, T3, T4, T5, T6, T7]   \n",
       "..                                    ...   \n",
       "345                  [T1, T2, T3, T4, T5]   \n",
       "346  [T1, T2, T3, T4, T5, T6, T7, T8, T9]   \n",
       "347              [T1, T2, T3, T4, T5, T6]   \n",
       "348              [T1, T2, T3, T4, T5, T6]   \n",
       "349              [T1, T2, T5, T6, T7, T8]   \n",
       "\n",
       "                                               ac_type  \\\n",
       "0    [MajorClaim, Premise, Premise, Premise, Premis...   \n",
       "1    [Claim, Premise, Premise, Premise, Premise, Pr...   \n",
       "2    [Claim, Premise, Premise, Premise, Premise, Pr...   \n",
       "3    [MajorClaim, Premise, Premise, Premise, Premis...   \n",
       "4    [Premise, Premise, Premise, Premise, Claim, Pr...   \n",
       "..                                                 ...   \n",
       "345        [Premise, Premise, Premise, Premise, Claim]   \n",
       "346  [Premise, Premise, Premise, Premise, Premise, ...   \n",
       "347  [Premise, Premise, Premise, Premise, Claim, Cl...   \n",
       "348  [Premise, Premise, Premise, Premise, Premise, ...   \n",
       "349  [Claim, Premise, Premise, Premise, Premise, Cl...   \n",
       "\n",
       "                                        ac_start_bound  \\\n",
       "0               [1, 992, 1063, 1188, 1452, 1569, 1769]   \n",
       "1              [1, 1354, 1443, 1593, 1828, 1979, 2056]   \n",
       "2    [1, 957, 1204, 1297, 1465, 1612, 1865, 1938, 2...   \n",
       "3      [218, 1028, 1209, 1395, 1580, 1647, 1844, 2193]   \n",
       "4              [552, 678, 758, 1102, 1196, 1228, 1306]   \n",
       "..                                                 ...   \n",
       "345                      [812, 1026, 1140, 1342, 1469]   \n",
       "346  [983, 1124, 1187, 1250, 1327, 1349, 1503, 1624...   \n",
       "347               [1149, 1215, 1381, 1507, 2258, 2523]   \n",
       "348                [891, 1041, 1139, 1264, 1357, 1578]   \n",
       "349                  [1, 1260, 1451, 1564, 1644, 1737]   \n",
       "\n",
       "                                          ac_end_bound  \\\n",
       "0            [162, 1058, 1187, 1447, 1568, 1768, 1945]   \n",
       "1            [318, 1442, 1592, 1827, 1978, 2055, 2167]   \n",
       "2    [156, 1203, 1296, 1464, 1611, 1864, 1928, 2001...   \n",
       "3      [449, 1208, 1394, 1579, 1646, 1843, 2152, 2288]   \n",
       "4             [677, 757, 1101, 1195, 1227, 1305, 1555]   \n",
       "..                                                 ...   \n",
       "345                     [1025, 1139, 1341, 1468, 1760]   \n",
       "346  [1123, 1186, 1249, 1326, 1348, 1502, 1623, 166...   \n",
       "347               [1214, 1380, 1506, 1699, 2522, 2655]   \n",
       "348               [1040, 1138, 1263, 1356, 1577, 1770]   \n",
       "349                [154, 1450, 1563, 1643, 1736, 1841]   \n",
       "\n",
       "                                                    ac    type_indicator_y  \\\n",
       "0    [A combination of mitoxantrone plus prednisone...  [R, R, R, R, R, R]   \n",
       "1    [In endocrine therapy trials in advanced breas...     [R, R, R, R, R]   \n",
       "2    [Treatment with cisplatin-based chemotherapy p...     [R, R, R, R, R]   \n",
       "3    [In nonrandomized studies involving patients w...     [R, R, R, R, R]   \n",
       "4    [Overall objective response (OR) rates were hi...        [R, R, R, R]   \n",
       "..                                                 ...                 ...   \n",
       "345  [With a median follow-up of 13 months, the ove...           [R, R, R]   \n",
       "346  [Patients in the chemotherapy group reported b...     [R, R, R, R, R]   \n",
       "347  [Complete remission was achieved in 91% (170/1...        [R, R, R, R]   \n",
       "348  [An objective response (complete [CR] or parti...           [R, R, R]   \n",
       "349  [Vinorelbine, a semisynthetic vinca alkaloid, ...     [R, R, R, R, R]   \n",
       "\n",
       "                       source                    target  \\\n",
       "0    [T8, T2, T3, T6, T4, T7]  [T1, T8, T8, T8, T8, T1]   \n",
       "1        [T7, T3, T4, T5, T6]      [T8, T8, T8, T8, T8]   \n",
       "2        [T8, T6, T2, T4, T5]      [T9, T9, T9, T9, T9]   \n",
       "3        [T2, T4, T5, T6, T7]      [T8, T8, T8, T8, T8]   \n",
       "4            [T1, T3, T4, T5]          [T7, T7, T7, T7]   \n",
       "..                        ...                       ...   \n",
       "345              [T4, T3, T1]              [T5, T5, T5]   \n",
       "346      [T5, T1, T3, T6, T7]      [T4, T9, T2, T9, T9]   \n",
       "347          [T1, T4, T3, T2]          [T6, T6, T5, T5]   \n",
       "348              [T4, T5, T3]              [T6, T6, T6]   \n",
       "349      [T8, T5, T6, T2, T7]      [T1, T8, T8, T8, T8]   \n",
       "\n",
       "                                         relation_type     text_file  \\\n",
       "0    [Support, Support, Support, Support, Support, ...  10561201.txt   \n",
       "1          [Attack, Support, Support, Support, Attack]  10561203.txt   \n",
       "2        [Support, Support, Support, Support, Support]  10653877.txt   \n",
       "3        [Support, Support, Support, Support, Support]  10675381.txt   \n",
       "4                 [Support, Support, Support, Support]  10735887.txt   \n",
       "..                                                 ...           ...   \n",
       "345                        [Support, Support, Support]   9807987.txt   \n",
       "346        [Attack, Support, Attack, Support, Support]   9849452.txt   \n",
       "347               [Support, Support, Support, Support]   9849454.txt   \n",
       "348                        [Support, Support, Support]   9850014.txt   \n",
       "349      [Support, Support, Support, Support, Support]   9890172.txt   \n",
       "\n",
       "                                         abstract_text  \n",
       "0     A combination of mitoxantrone plus prednisone...  \n",
       "1     In endocrine therapy trials in advanced breas...  \n",
       "2     Treatment with cisplatin-based chemotherapy p...  \n",
       "3     Extracellular adenosine 5'-triphosphate (ATP)...  \n",
       "4     This phase III, double-blind, randomized, mul...  \n",
       "..                                                 ...  \n",
       "345   In phase II studies, irinotecan is active in ...  \n",
       "346   The aim of the present trial was to evaluate ...  \n",
       "347   The second International Society of Paediatri...  \n",
       "348   We report results of a randomized prospective...  \n",
       "349   Vinorelbine, a semisynthetic vinca alkaloid, ...  \n",
       "\n",
       "[350 rows x 13 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_abs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_src_acs(row):\n",
    "    try:\n",
    "        source_ids = row.source\n",
    "\n",
    "        source_acs = [row.ac[row.ac_id.index(elem)] for elem in source_ids if elem != None]\n",
    "\n",
    "        return source_acs\n",
    "\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error at index {row.name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trg_acs(row):\n",
    "    try:\n",
    "        target_ids = row.target\n",
    "        target_acs = [row.ac[row.ac_id.index(elem)] for elem in target_ids if elem != None]\n",
    "\n",
    "        return target_acs\n",
    "\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error at index {row.name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_src_ids(row):\n",
    "    try:\n",
    "        \n",
    "        source_acs = row.source_acs\n",
    "        source_ids = [row.ac.index(elem)+1 for elem in source_acs]\n",
    "\n",
    "        return source_ids\n",
    "\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error at index {row.name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trg_ids(row):\n",
    "    try:\n",
    "        \n",
    "        target_acs = row.target_acs\n",
    "        target_ids = [row.ac.index(elem)+1 for elem in target_acs]\n",
    "\n",
    "        return target_ids\n",
    "\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error at index {row.name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_relations(row):\n",
    "    \n",
    "    return [(i, j) for i, j in zip(row.source_ids, row.target_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_abs['source_acs'] = train_df_abs.apply(lambda row: get_src_acs(row), axis=1)\n",
    "train_df_abs['target_acs'] = train_df_abs.apply(lambda row: get_trg_acs(row), axis=1)\n",
    "\n",
    "train_df_abs['source_ids'] = train_df_abs.apply(lambda row: get_src_ids(row), axis=1)\n",
    "train_df_abs['target_ids'] = train_df_abs.apply(lambda row: get_trg_ids(row), axis=1)\n",
    "\n",
    "train_df_abs['relations'] = train_df_abs.apply(lambda row: build_relations(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df_abs['source_acs'] = dev_df_abs.apply(lambda row: get_src_acs(row), axis=1)\n",
    "dev_df_abs['target_acs'] = dev_df_abs.apply(lambda row: get_trg_acs(row), axis=1)\n",
    "\n",
    "dev_df_abs['source_ids'] = dev_df_abs.apply(lambda row: get_src_ids(row), axis=1)\n",
    "dev_df_abs['target_ids'] = dev_df_abs.apply(lambda row: get_trg_ids(row), axis=1)\n",
    "\n",
    "dev_df_abs['relations'] = dev_df_abs.apply(lambda row: build_relations(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "gla_test_df_abs['source_acs'] = gla_test_df_abs.apply(lambda row: get_src_acs(row), axis=1)\n",
    "gla_test_df_abs['target_acs'] = gla_test_df_abs.apply(lambda row: get_trg_acs(row), axis=1)\n",
    "\n",
    "gla_test_df_abs['source_ids'] = gla_test_df_abs.apply(lambda row: get_src_ids(row), axis=1)\n",
    "gla_test_df_abs['target_ids'] = gla_test_df_abs.apply(lambda row: get_trg_ids(row), axis=1)\n",
    "\n",
    "gla_test_df_abs['relations'] = gla_test_df_abs.apply(lambda row: build_relations(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_test_df_abs['source_acs'] = mix_test_df_abs.apply(lambda row: get_src_acs(row), axis=1)\n",
    "mix_test_df_abs['target_acs'] = mix_test_df_abs.apply(lambda row: get_trg_acs(row), axis=1)\n",
    "\n",
    "mix_test_df_abs['source_ids'] = mix_test_df_abs.apply(lambda row: get_src_ids(row), axis=1)\n",
    "mix_test_df_abs['target_ids'] = mix_test_df_abs.apply(lambda row: get_trg_ids(row), axis=1)\n",
    "\n",
    "mix_test_df_abs['relations'] = mix_test_df_abs.apply(lambda row: build_relations(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "neo_test_df_abs['source_acs'] = neo_test_df_abs.apply(lambda row: get_src_acs(row), axis=1)\n",
    "neo_test_df_abs['target_acs'] = neo_test_df_abs.apply(lambda row: get_trg_acs(row), axis=1)\n",
    "\n",
    "neo_test_df_abs['source_ids'] = neo_test_df_abs.apply(lambda row: get_src_ids(row), axis=1)\n",
    "neo_test_df_abs['target_ids'] = neo_test_df_abs.apply(lambda row: get_trg_ids(row), axis=1)\n",
    "\n",
    "neo_test_df_abs['relations'] = neo_test_df_abs.apply(lambda row: build_relations(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_egalite(row):\n",
    "    \n",
    "    return 1 if (len(row.relation_type) == len(row.relations)) and (len(row.ac) == len(row.ac_type)) else 0     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "neo_test_df_abs['egalite'] = neo_test_df_abs.apply(lambda row: check_egalite(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "egalite\n",
       "1    100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neo_test_df_abs['egalite'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ok cause the 7 have no relations train. 2 in gla. 2 in mix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATFILES_DIR = Path(\"/Utilisateurs/umushtaq/am_reasoning/abstRCT/data_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_abs.to_csv(DATFILES_DIR / \"neo_train.csv\")\n",
    "dev_df_abs.to_csv(DATFILES_DIR / \"neo_dev.csv\")\n",
    "gla_test_df_abs.to_csv(DATFILES_DIR / \"gla_test.csv\")\n",
    "mix_test_df_abs.to_csv(DATFILES_DIR / \"mix_test.csv\")\n",
    "neo_test_df_abs.to_csv(DATFILES_DIR / \"neo_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (17M_env)",
   "language": "python",
   "name": "17m_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
